{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model works to estimate the prices based on the following features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing modules\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras as K\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103378.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1962661.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52707.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1902874.0</td>\n",
       "      <td>Adjuntas</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>601.0</td>\n",
       "      <td>1527.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103379.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1404990.0</td>\n",
       "      <td>Juana Diaz</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>795.0</td>\n",
       "      <td>748.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31239.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1947675.0</td>\n",
       "      <td>Ponce</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>731.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34632.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>331151.0</td>\n",
       "      <td>Mayaguez</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brokered_by    status     price  ...  zip_code  house_size  prev_sold_date\n",
       "0     103378.0  for_sale  105000.0  ...     601.0       920.0             NaN\n",
       "1      52707.0  for_sale   80000.0  ...     601.0      1527.0             NaN\n",
       "2     103379.0  for_sale   67000.0  ...     795.0       748.0             NaN\n",
       "3      31239.0  for_sale  145000.0  ...     731.0      1800.0             NaN\n",
       "4      34632.0  for_sale   65000.0  ...     680.0         NaN             NaN\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_only = df[df['state'] == 'New Jersey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df = state_df_only[state_df_only['status'] == 'for_rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48199"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_duplicate = pd.concat([state_df,state_df,state_df,state_df,state_df,state_df,state_df,state_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_df_cleaned= state_df_duplicate.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129520"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brokered_by</th>\n",
       "      <th>status</th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "      <th>prev_sold_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16709.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>339900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>893593.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1456.0</td>\n",
       "      <td>1987-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60594.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>305100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>169015.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>2022-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53550.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1354688.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1870.0</td>\n",
       "      <td>2002-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>81259.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>863208.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>2015-11-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>48366.0</td>\n",
       "      <td>for_sale</td>\n",
       "      <td>399000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>190536.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1476.0</td>\n",
       "      <td>1990-02-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    brokered_by    status     price  ...  zip_code  house_size  prev_sold_date\n",
       "1       16709.0  for_sale  339900.0  ...    7001.0      1456.0      1987-05-20\n",
       "2       60594.0  for_sale  305100.0  ...    7001.0      1542.0      2022-01-27\n",
       "5       53550.0  for_sale  325000.0  ...    7001.0      1870.0      2002-12-17\n",
       "8       81259.0  for_sale  440000.0  ...    7001.0      1842.0      2015-11-23\n",
       "10      48366.0  for_sale  399000.0  ...    7001.0      1476.0      1990-02-28\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brokered_by', 'status', 'price', 'bed', 'bath', 'acre_lot', 'street',\n",
       "       'city', 'state', 'zip_code', 'house_size', 'prev_sold_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b8/466710_d78q31z8wgrvw2cc00000gn/T/ipykernel_83026/1652658617.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  state_df_cleaned.drop(['brokered_by', 'status','prev_sold_date'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#state_df_cleaned.drop(['brokered_by', 'status','prev_sold_date'], axis=1, inplace=True)\n",
    "state_df_cleaned.drop(['brokered_by', 'status','prev_sold_date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bed</th>\n",
       "      <th>bath</th>\n",
       "      <th>acre_lot</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>house_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>339900.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>893593.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1456.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>305100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>169015.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1354688.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>440000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>863208.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1842.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>399000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>190536.0</td>\n",
       "      <td>Avenel</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>7001.0</td>\n",
       "      <td>1476.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  bed  bath  acre_lot  ...    city       state zip_code  house_size\n",
       "1   339900.0  2.0   2.0      0.11  ...  Avenel  New Jersey   7001.0      1456.0\n",
       "2   305100.0  3.0   2.0      0.14  ...  Avenel  New Jersey   7001.0      1542.0\n",
       "5   325000.0  3.0   3.0      0.15  ...  Avenel  New Jersey   7001.0      1870.0\n",
       "8   440000.0  4.0   2.0      0.17  ...  Avenel  New Jersey   7001.0      1842.0\n",
       "10  399000.0  3.0   3.0      0.06  ...  Avenel  New Jersey   7001.0      1476.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=state_df_cleaned.drop(['rent'], axis=1)\n",
    "y=state_df_cleaned['rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = ['bed', 'bath', 'acre_lot', 'house_size','zip_code','street','price']\n",
    "categorical_features = ['city', 'state']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = pipeline.fit_transform(X_train)\n",
    "X_test_preprocessed = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103616, 667)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train_preprocessed.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer with a single neuron for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2591/2591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 799us/step - loss: 644065198080.0000 - val_loss: 404677165056.0000\n",
      "Epoch 2/5\n",
      "\u001b[1m2591/2591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 638us/step - loss: 399794274304.0000 - val_loss: 231683915776.0000\n",
      "Epoch 3/5\n",
      "\u001b[1m2591/2591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - loss: 289047412736.0000 - val_loss: 219371356160.0000\n",
      "Epoch 4/5\n",
      "\u001b[1m2591/2591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 578us/step - loss: 267993858048.0000 - val_loss: 212751302656.0000\n",
      "Epoch 5/5\n",
      "\u001b[1m2591/2591\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - loss: 270578565120.0000 - val_loss: 206486978560.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train_preprocessed, y_train, epochs=5, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m810/810\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step - loss: 214837264384.0000\n",
      "Test Loss: 232756740096.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test_preprocessed, y_test)\n",
    "print(f'Test Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "Predicted Price: 516111.38\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on new data\n",
    "new_data = pd.DataFrame({\n",
    "    'bed': [4],\n",
    "    'bath': [3],\n",
    "    'acre_lot': [0.8],\n",
    "    'street': [893593.0],\n",
    "    'city': ['Newark'],\n",
    "    'state': ['New Jersey'],\n",
    "    'house_size': [2200],\n",
    "    'zip_code': [7003],\n",
    "    'price': [100000]\n",
    "})\n",
    "\n",
    "# Preprocess the new data\n",
    "new_data_preprocessed = pipeline.transform(new_data)\n",
    "\n",
    "# Predict the price\n",
    "predicted_price = model.predict(new_data_preprocessed)\n",
    "print(f'Predicted Rent: {predicted_price[0][0]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('rent_price_prediction_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATISTICAL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Wed, 03 Jul 2024   Prob (F-statistic):                nan\n",
      "Time:                        09:15:02   Log-Likelihood:                 72.301\n",
      "No. Observations:                   4   AIC:                            -136.6\n",
      "Df Residuals:                       0   BIC:                            -139.1\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const      -9953.1103        inf         -0        nan         nan         nan\n",
      "x1         -1.544e+04        inf         -0        nan         nan         nan\n",
      "x2          3.624e+04        inf          0        nan         nan         nan\n",
      "x3          1.178e+04        inf          0        nan         nan         nan\n",
      "x4         -3665.8087        inf         -0        nan         nan         nan\n",
      "x5         -3665.8087        inf         -0        nan         nan         nan\n",
      "x6         -2.175e+04        inf         -0        nan         nan         nan\n",
      "x7         -1.179e+04        inf         -0        nan         nan         nan\n",
      "x8           676.1635        inf          0        nan         nan         nan\n",
      "x9           212.2933        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.212\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.811\n",
      "Skew:                          -1.037   Prob(JB):                        0.667\n",
      "Kurtosis:                       2.251   Cond. No.                     5.95e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n",
      "[3] The condition number is large, 5.95e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1796: RuntimeWarning: divide by zero encountered in divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1796: RuntimeWarning: invalid value encountered in scalar multiply\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1718: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'price': [220000, 270000, 320000, 370000],\n",
    "    'beds': [3, 4, 3, 5],\n",
    "    'baths': [2, 3, 2, 4],\n",
    "    'acre_lot': [0.5, 0.75, 0.6, 1.0],\n",
    "    'street': ['A St', 'B St', 'C St', 'D St'],\n",
    "    'city': ['City1', 'City2', 'City1', 'City2'],\n",
    "    'state': ['State1', 'State2', 'State1', 'State2'],\n",
    "    'house_size': [1500, 2000, 1800, 2500],\n",
    "    'rent': [220000, 270000, 320000, 370000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the dataset into features (X) and target (y)\n",
    "X = df.drop('rent', axis=1)\n",
    "y = df['rent']\n",
    "\n",
    "# Define the preprocessing steps\n",
    "categorical_features = ['street', 'city', 'state']\n",
    "numerical_features = ['beds', 'baths', 'acre_lot', 'house_size','price']\n",
    "\n",
    "# Define the column transformer with OneHotEncoder for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features),\n",
    "        ('num', 'passthrough', numerical_features)\n",
    "    ])\n",
    "\n",
    "# Apply the transformations\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "# Ensure X_encoded is a 2D array\n",
    "X_encoded = np.asarray(X_encoded)\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X_encoded = sm.add_constant(X_encoded)\n",
    "\n",
    "# Ensure y is a 1D array\n",
    "y_np = np.asarray(y)\n",
    "\n",
    "# Create the OLS regression model\n",
    "stat_model = sm.OLS(y_np, X_encoded)\n",
    "\n",
    "# Fit the model\n",
    "results = stat_model.fit()\n",
    "\n",
    "# Print the model summary\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of model coefficients: (10,)\n",
      "Shape of new data: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "new_data = {\n",
    "    'beds': [4],\n",
    "    'baths': [3],\n",
    "    'acre_lot': [0.8],\n",
    "    'street': ['B St'],\n",
    "    'city': ['City2'],\n",
    "    'state': ['State1'],\n",
    "    'house_size': [2200]\n",
    "}\n",
    "\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Apply the same preprocessing to the new data\n",
    "new_X_encoded = preprocessor.transform(new_df)\n",
    "\n",
    "# Add a constant term to the new data\n",
    "new_X_encoded = sm.add_constant(new_X_encoded,has_constant='add')\n",
    "\n",
    "# Ensure new_X_encoded is a 2D array\n",
    "new_X_encoded = np.asarray(new_X_encoded)\n",
    "\n",
    "# Check shapes to ensure alignment\n",
    "print(\"Shape of model coefficients:\", results.params.shape)\n",
    "print(\"Shape of new data:\", new_X_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted prices: [316158.269887]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions using the fitted model\n",
    "predictions = results.predict(new_X_encoded)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predicted prices:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
